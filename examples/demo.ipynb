{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cbe5246",
   "metadata": {},
   "source": [
    "# pdf_agent examples demo\n",
    "\n",
    "This notebook combines three small demos used in the blog series:\n",
    "1. Ingest PDFs into the vector index\n",
    "2. Run a retrieval query and save the JSON result\n",
    "3. Run a comprehensive `analyze_all` job and save the long-form output\n",
    "\n",
    "Notes:\n",
    "- The notebook uses the repository's `PDFAgent` class (from `agents/pdf_agent.py`).\n",
    "- Ensure you have the environment configured and `system_config.json` or environment variables set for any cloud providers you plan to use.\n",
    "- Create an `outputs/` directory before running cells (`outputs/` is used to store results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63047dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: imports and agent initialization\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Import the agent (uses repo code)\n",
    "from agents.pdf_agent import PDFAgent\n",
    "\n",
    "# Ensure outputs directory exists\n",
    "Path('outputs').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Instantiate the agent (may print logs)\n",
    "agent = PDFAgent()\n",
    "print('PDFAgent initialized. Use `agent` to run ingestion, retrieval and analyze_all.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff12065c",
   "metadata": {},
   "source": [
    "## Demo 1 — Ingest a folder of PDFs\n",
    "\n",
    "This cell will parse and index PDF files found in `downloads/search_results` by default. Update `folder` to point to your PDF directory. For small test sets (2–3 PDFs) this is quick; for hundreds of PDFs it may take much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest demo (adjust `folder` as needed)\n",
    "folder = Path('downloads/search_results')\n",
    "\n",
    "if not folder.exists():\n",
    "    print(f'Folder not found: {folder.resolve()}')\n",
    "    print('Update the `folder` variable to the path where your PDFs are stored.')\n",
    "else:\n",
    "    print(f'Ingesting PDFs from: {folder.resolve()}')\n",
    "    result = agent.process_folder(folder)\n",
    "    print('Ingest result:')\n",
    "    print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddfa8dc",
   "metadata": {},
   "source": [
    "## Demo 2 — Retrieval (RAG)\n",
    "\n",
    "This cell runs a retrieval query using the agent's `search` API (mode: `enhanced` by default). The returned result will be saved to `outputs/retrieve_result.json`. If the index is empty, run the ingest cell first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba10929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval demo\n",
    "query = 'What are agentic workflows?'\n",
    "mode = 'enhanced'\n",
    "print(f'Running query (mode={mode}): {query}')\n",
    "try:\n",
    "    res = agent.search(query, mode=mode)\n",
    "except RuntimeError:\n",
    "    print('Search not ready: index may be empty. Run ingestion first.')\n",
    "    raise\n",
    "\n",
    "print('\n",
    "--- ANSWER ---')\n",
    "print(res.get('answer', '(no answer)'))\n",
    "\n",
    "out_path = Path('outputs/retrieve_result.json')\n",
    "with out_path.open('w') as fh:\n",
    "    json.dump(res, fh, indent=2)\n",
    "\n",
    "print(f'Query result saved to: {out_path.resolve()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3f041",
   "metadata": {},
   "source": [
    "## Demo 3 — Comprehensive analysis (`analyze_all`)\n",
    "\n",
    "The `analyze_all` mode performs a batched analysis across the entire indexed corpus and can produce long outputs. Use a short query and expect longer runtimes. The notebook saves the final text to `outputs/analyze_all_result.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze-all demo (may take significant time on large corpora)\n",
    "query = 'Summarize recent trends in agentic AI'\n",
    "print('Starting analyze_all; this may take a while depending on corpus size...')\n",
    "result = agent.search(query, mode='analyze_all')\n",
    "answer = result.get('answer', '(no answer)')\n",
    "out_file = Path('outputs/analyze_all_result.txt')\n",
    "out_file.write_text(answer)\n",
    "print(f'Analyze_all output saved to: {out_file.resolve()}')\n",
    "print(f'Documents analyzed: {len(result.get(\"sources\", []))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ebd2f4",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- If you plan to use cloud providers (Azure/Poe), verify `system_config.json` and your environment variables before ingesting large corpora.\n",
    "- For privacy-sensitive data, consider running Ollama locally and selecting it as the embedding/LLM provider in settings.\n",
    "- Use the `examples/` CLI scripts if you prefer non-interactive runs.\n",
    "\n",
    "If you want, I can split this notebook into smaller tutorial notebooks (one per blog post) or produce an HTML-exported demo for distribution."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
